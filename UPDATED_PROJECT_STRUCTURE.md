# ğŸ“ KARUI-SEARCH PROJECT STRUCTURE (Updated)

## ğŸš€ **Root Directory** (Clean & Organized)

```
karuisearch/
â”œâ”€â”€ ğŸ“‹ CLAUDE.md                     # Project instructions for AI
â”œâ”€â”€ ğŸ“‹ README.md                     # Main project documentation  
â”œâ”€â”€ ğŸ“‹ ARCHITECTURE.md               # System architecture
â”œâ”€â”€ ğŸ“‹ CHANGELOG.md                  # Version history
â”œâ”€â”€ ğŸ“‹ SCRAPER_MACROS_GUIDE.md      # Scraper usage guide
â”œâ”€â”€ ğŸ“‹ UPDATED_PROJECT_STRUCTURE.md  # This file
â”œâ”€â”€ ğŸ”§ package.json                  # Node.js dependencies (root)
â”œâ”€â”€ ğŸ”§ requirements.txt              # Python dependencies
â”œâ”€â”€ ğŸ“ config/                       # Configuration files
â”œâ”€â”€ ğŸ“ database/                     # Database schemas
â”œâ”€â”€ ğŸ“ docs/                         # Documentation
â”œâ”€â”€ ğŸ“ scripts/                      # ğŸ†• ALL EXECUTABLE FILES HERE
â”œâ”€â”€ ğŸ“ src/                          # Source code (scrapers, frontend, utils)
â””â”€â”€ ğŸ“ node_modules/                 # Node dependencies (root)
```

## ğŸ“ **Scripts Directory** (All Executables)

```
scripts/
â”œâ”€â”€ ğŸ“„ README.md                      # Scripts documentation
â”œâ”€â”€ ğŸ generate_mock_data.py          # Main data generation script
â”œâ”€â”€ ğŸªŸ generate_mock_data.bat         # Windows batch for above

â”œâ”€â”€ ğŸš€ **Fast Scrapers** (2-3 minutes)
â”‚   â”œâ”€â”€ ğŸ run_scraper_fast.py        # Python script
â”‚   â”œâ”€â”€ ğŸªŸ run_scraper_fast.bat       # Interactive batch
â”‚   â””â”€â”€ ğŸªŸ run_scraper_fast_mock.bat  # Direct mock output

â”œâ”€â”€ âš–ï¸ **Balanced Scrapers** (3-5 minutes, 10 props/site)
â”‚   â”œâ”€â”€ ğŸ run_scraper_balanced.py    # Python script  
â”‚   â”œâ”€â”€ ğŸªŸ run_scraper_balanced.bat   # Interactive batch
â”‚   â””â”€â”€ ğŸªŸ run_scraper_balanced_mock.bat # Direct mock output

â”œâ”€â”€ ğŸ”§ **Other Scrapers**
â”‚   â”œâ”€â”€ ğŸªŸ run_scraper.bat            # Full scraping (10+ min)
â”‚   â”œâ”€â”€ ğŸªŸ run_scraper_quick.bat      # Mitsui only (30s)
â”‚   â””â”€â”€ ğŸ run_quick_scrape.py        # Quick test script

â”œâ”€â”€ ğŸ§ª **Test & Debug Scripts**
â”‚   â”œâ”€â”€ ğŸ test_*.py                  # Various test scripts
â”‚   â”œâ”€â”€ ğŸ debug_*.py                 # Debug utilities
â”‚   â”œâ”€â”€ ğŸ simple_*.py                # Simple test scripts
â”‚   â””â”€â”€ ğŸ demo_karui_search.py       # Demo script

â””â”€â”€ ğŸ“Š **Data & Logs**
    â”œâ”€â”€ ğŸ“„ *.csv                      # Test results
    â””â”€â”€ ğŸ“„ scraping.log               # Log files
```

## ğŸ“ **Source Code Structure**

```
src/
â”œâ”€â”€ ğŸ•·ï¸ **scrapers/** (Web Scraping Engine)
â”‚   â”œâ”€â”€ ğŸ base_scraper.py           # Abstract base classes
â”‚   â”œâ”€â”€ ğŸ browser_scraper.py        # Selenium browser automation  
â”‚   â”œâ”€â”€ ğŸ scraper_factory.py        # Scraper factory pattern
â”‚   â”œâ”€â”€ ğŸ mitsui_scraper.py         # Mitsui no Mori (âœ… Working)
â”‚   â”œâ”€â”€ ğŸ royal_resort_scraper.py   # Royal Resort (âœ… Working)
â”‚   â”œâ”€â”€ ğŸ besso_navi_scraper.py     # Besso Navi browser version
â”‚   â””â”€â”€ ğŸ besso_navi_http_scraper.py # Besso Navi HTTP version (âœ… Fixed)

â”œâ”€â”€ ğŸ› ï¸ **utils/** (Utilities)
â”‚   â””â”€â”€ ğŸ titleGenerator.py         # Property title generation

â””â”€â”€ ğŸŒ **frontend/** (React Application)
    â”œâ”€â”€ ğŸ“„ index.html                # Entry point
    â”œâ”€â”€ ğŸ”§ package.json              # Frontend dependencies
    â”œâ”€â”€ ğŸ”§ vite.config.ts            # Vite configuration
    â”œâ”€â”€ ğŸ”§ tsconfig.json             # TypeScript config
    â””â”€â”€ src/
        â”œâ”€â”€ ğŸ“„ App.tsx               # Main app component
        â”œâ”€â”€ ğŸ“„ main.tsx              # React entry
        â”œâ”€â”€ ğŸ“ components/           # UI components
        â”œâ”€â”€ ğŸ“ pages/                # Page components  
        â”œâ”€â”€ ğŸ“ data/                 # Mock data (JSON files)
        â”œâ”€â”€ ğŸ“ services/             # API services
        â”œâ”€â”€ ğŸ“ types/                # TypeScript types
        â”œâ”€â”€ ğŸ“ utils/                # Frontend utilities
        â”œâ”€â”€ ğŸ“ hooks/                # React hooks
        â””â”€â”€ ğŸ“ i18n/                 # Internationalization
```

## ğŸ¯ **Key Changes Made**

### âœ… **File Organization**
- **Moved ALL executable files** to `scripts/` directory
- **Updated all import paths** to use `../src/` 
- **Fixed all batch file paths** to run from scripts directory
- **Maintained clean root** with only documentation and config

### âœ… **Path Updates**
- Python scripts: `sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))`
- Mock output: `os.path.join("..", "src", "frontend", "src", "data")`
- Batch files: `cd /d "C:\Users\dougc\git\karuisearch\scripts"`

### âœ… **Maintained Functionality**
- All scrapers still work correctly
- `--writemock` flag still outputs to frontend data directory
- Batch files run from their new location
- Import paths correctly resolve to source code

## ğŸš€ **How to Use**

### **From Root Directory:**
```bash
# Navigate to scripts
cd scripts

# Run any scraper
./run_scraper_fast_mock.bat
python generate_mock_data.py
```

### **Direct Execution:**
```bash
# Double-click any .bat file in scripts/ folder
# They will automatically set correct working directory
```

## ğŸ“Š **Current Status**

| Component | Status | Location |
|-----------|--------|----------|
| **All Scrapers** | âœ… Working | `scripts/` |
| **Mock Data Generation** | âœ… Working | `scripts/generate_mock_data.py` |
| **Batch Macros** | âœ… Updated | `scripts/*.bat` |
| **Frontend Integration** | âœ… Working | `src/frontend/src/data/` |
| **Image Extraction** | âœ… Fixed | All scrapers extracting images |

## ğŸ‰ **Benefits of New Structure**

- **ğŸ§¹ Clean root directory** - Only docs and config at top level
- **ğŸ“ Organized scripts** - All executables in one place  
- **ğŸ”„ Easy execution** - Double-click any batch file
- **ğŸ› ï¸ Developer friendly** - Clear separation of concerns
- **ğŸ“¦ Maintainable** - Easy to find and update scripts

**Your project is now perfectly organized and all scrapers are working with full image extraction!** ğŸš€